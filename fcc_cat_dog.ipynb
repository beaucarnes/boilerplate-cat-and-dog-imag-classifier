{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la_Oz6oLlub6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaF8r6aOl48C"
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOJFeEfumns6"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Basic data generators\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_data_gen = validation_image_generator.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_data_gen = test_image_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "def plotImages(images_arr, probabilities = False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
        "    if len(images_arr) == 1:\n",
        "        axes = [axes]\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    if probabilities is False:\n",
        "        plt.show()\n",
        "        return\n",
        "    for i, ax in enumerate(axes):\n",
        "        if probabilities[i] > 0.5:\n",
        "            ax.set_title(\"%.2f\" % (probabilities[i]*100) + \"% dog\")\n",
        "        else:\n",
        "            ax.set_title(\"%.2f\" % ((1-probabilities[i])*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "augmented_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=45,\n",
        "    width_shift_range=.15,\n",
        "    height_shift_range=.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.5,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS"
      },
      "outputs": [],
      "source": [
        "train_data_gen_augmented = augmented_image_generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8aZkwMam4UY"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu',\n",
        "                          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_data_gen_augmented,\n",
        "    steps_per_epoch=train_data_gen.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_data_gen,\n",
        "    validation_steps=validation_data_gen.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Visualize results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYrSifOit2aK"
      },
      "outputs": [],
      "source": [
        "test_path = os.path.join(PATH, 'test')\n",
        "if not os.path.exists(test_path):\n",
        "    print(\"Note: Test directory not found. Make sure to create it and add test images.\")\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_data_gen = test_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_data_gen.samples > 0:\n",
        "    predictions = model.predict(test_data_gen, steps=test_data_gen.samples)\n",
        "    print(f\"Predictions shape: {predictions.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_test_images(test_dir, img_height, img_width):\n",
        "    test_images = []\n",
        "    test_files = sorted([f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "\n",
        "    for filename in test_files:\n",
        "        img_path = os.path.join(test_dir, filename)\n",
        "        img = load_img(img_path, target_size=(img_height, img_width))\n",
        "        img_array = img_to_array(img)\n",
        "        img_array = img_array / 255.0  # Rescale\n",
        "        test_images.append(img_array)\n",
        "\n",
        "    return np.array(test_images)\n",
        "\n",
        "# Load and preprocess test images\n",
        "test_images = load_test_images(test_dir, IMG_HEIGHT, IMG_WIDTH)\n",
        "\n",
        "if len(test_images) > 0:\n",
        "    # Make predictions\n",
        "    probabilities = model.predict(test_images)\n",
        "\n",
        "    # Plot results\n",
        "    plotImages(test_images, probabilities)\n",
        "else:\n",
        "    print(\"No test images found in directory:\", test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IH86Ux_u7TZ"
      },
      "outputs": [],
      "source": [
        "answers = [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "           1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "           1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "           1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "           0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0\n",
        "\n",
        "# Iterate through probabilities and answers, rounding each probability\n",
        "for probability, answer in zip(probabilities.flatten(), answers):\n",
        "    if round(float(probability)) == answer:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate the percentage of correctly identified images\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "# Check if the model passes the challenge\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "    print(\"You passed the challenge!\")\n",
        "else:\n",
        "    print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fcc_cat_dog.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
